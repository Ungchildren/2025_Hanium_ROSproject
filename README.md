##2025_Hanium_ROSproject

2025 í•œì´ìŒ ë“œë¦¼ì—… ICT ê³µëª¨ì „ ì¥ë ¤ìƒ (Honorable Mention, KAIT)

A real-time disaster rescue robot for GPS-denied environments using multi-sensor data fusion (LiDAR, IMU, Wheel Encoder, Camera, Temperature/Humidity).

ğŸ”— Links

ğŸ¥ Demo Video â†’ YouTube Link

ğŸ“„ Paper â†’ â€œReal-Time Disaster Rescue Robot for GPS-Denied Environments Using Multi-Sensor Data Fusion,â€
Korea Information Technology Society, Nov. 2025

ğŸ§  Team â†’ Hanium Dream-Up 2025 Project Page
 (optional)

ğŸ§© Background

Modern disaster environments often block GPS signals (e.g., tunnels, basements, or dense urban areas).
This project proposes a multi-sensor fusion robot system capable of real-time localization, mapping, and autonomous navigation in such GPS-denied environments.

Key Objectives:

Replace unreliable GPS data with LiDARâ€“IMUâ€“Odometry fusion (LIO).

Perform real-time SLAM and path planning on a Linux-based ROS2 system.

Provide cloud-based monitoring through MongoDB Atlas and Node-RED.

Detect environmental hazards with YOLOv5 and onboard cameras.

âš™ï¸ Environment Setup
Category	Details
OS	Ubuntu 20.04 LTS
Framework	ROS2 Foxy, Navigation2, Cartographer
Programming	Python 3, C++
Hardware	Raspberry Pi 4, Stella N2 Robot
Sensors	LiDAR (YDLidar X4PRO), IMU (MW-AHRSv2U), Wheel Encoder, GPS (EZ-0048), Temp/Humidity Sensor
Database / Monitoring	MongoDB Atlas, Node-RED
AI Model	YOLOv5 (custom trained for obstacle detection)

#System architecture
<img width="972" height="625" alt="image" src="https://github.com/user-attachments/assets/5227d894-40b7-4a96-a4eb-fbb972524345" />
System

<img width="959" height="642" alt="image" src="https://github.com/user-attachments/assets/eaf8da6a-4658-474c-819f-b097c7bb600d" />
Hardware

<img width="1337" height="620" alt="image" src="https://github.com/user-attachments/assets/82e0d6e4-ddb8-4f9d-bc54-49870729c32b" />
Software

<img width="1893" height="1155" alt="image" src="https://github.com/user-attachments/assets/62a25a0c-25c0-43c5-ba43-f65bd10baf42" />
Node-RED diagram

ğŸ§  Built With

ROS2 (Foxy) â€“ SLAM, Navigation, and real-time sensor fusion

Cartographer â€“ LiDAR-Inertial SLAM implementation

YOLOv5 â€“ Real-time object detection for hazard identification

MongoDB Atlas â€“ Cloud data storage for live sensor updates

Node-RED Dashboard â€“ Web-based real-time monitoring

Raspberry Pi 4 + Stella N2 â€“ Embedded control and execution platform

ğŸ“Š Results

Stable autonomous navigation in GPS-denied indoor environments

<img width="1694" height="812" alt="image" src="https://github.com/user-attachments/assets/0c4860cf-5545-40ec-9fa9-354de3e2eee7" />
Web Dashboard
description
- Real-time SLAM mapping and object detection
- End-to-end monitoring pipeline from robot â†’ cloud â†’ web

Result Youtube
https://youtu.be/2Iq2_ShP6eY?si=E3-j7cPRBcZmXgdn

ğŸ… Honorable Mention (KAIT Hanium Dream-Up ICT Competition 2025)
